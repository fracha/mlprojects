{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import time\n",
    "import collections\n",
    "import random\n",
    "import timeit\n",
    "import math\n",
    "\n",
    "import scipy,sklearn,pylab\n",
    "from scipy import io\n",
    "\n",
    "from sklearn import model_selection,covariance\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "matplotlib.rcParams['xtick.direction'] = 'out'\n",
    "matplotlib.rcParams['ytick.direction'] = 'out'\n",
    "matplotlib.rcParams['figure.figsize'] = (9,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readfile(path, cols):\n",
    "    with open(path) as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        q=list(reader)\n",
    "    s = [dict(([a,'-1'] if (x=='') else [a,x]) for a,x in b.items()) for b in q]\n",
    "    return [dict((\n",
    "        [a,float(x)] if a in cols else [a,x]) for a,x in b.items()) for b in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeneg(data,n=None):    \n",
    "    def f(data,n=None):\n",
    "        a = data[data!=-1]\n",
    "        if n:\n",
    "            m=n\n",
    "        else:\n",
    "            m = np.median(a)\n",
    "        for i in range(len(data)):\n",
    "            if (data==-1)[i]:\n",
    "                data[i]=m\n",
    "        return m\n",
    "    l = []\n",
    "    if n:\n",
    "        for i in range(data.shape[1]):\n",
    "            f(data[:,i],n[i])\n",
    "    else:\n",
    "         for i in range(data.shape[1]):\n",
    "            l.append(f(data[:,i]))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = readfile(\"hw5_titanic_dist/titanic_training.csv\",[\n",
    "    'pclass','age','sibsp','parch','fare'])\n",
    "\n",
    "titanic_labels = np.array([z.pop('survived') for z in s]).astype(\n",
    "    float).astype(int)\n",
    "r = readfile(\"hw5_titanic_dist/titanic_testing_data.csv\",[\n",
    "    'pclass','age','sibsp','parch','fare'])\n",
    "\n",
    "t = s+r\n",
    "\n",
    "v= sklearn.feature_extraction.DictVectorizer(sparse=False,sort=False)\n",
    "titanic_hot = v.fit_transform(t)\n",
    "titanic_hot_train = titanic_hot[:1000,:]\n",
    "titanic_test = titanic_hot[1000:,:]\n",
    "\n",
    "titanic_feat_names = v.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_medians = removeneg(titanic_hot_train)\n",
    "removeneg(titanic_test,t_medians)\n",
    "#titanic_hot_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#v.inverse_transform(titanic_hot_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spam= scipy.io.loadmat(\"hw5_spam_dist/dist/spam_data\")\n",
    "#spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spam_train = spam['training_data']\n",
    "spam_labels = spam['training_labels'][0]\n",
    "spam_test = spam['test_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s= readfile(\"hw5_census_dist/train_data.csv\",[\n",
    "    'capital-gain','capital-loss','age','hours-per-week',\n",
    "    'education-num','fnlwgt'])\n",
    "census_labels = np.array([z.pop('label') for z in s]).astype(int)\n",
    "r = readfile(\"hw5_census_dist/test_data.csv\",[\n",
    "    'capital-gain','capital-loss','age','hours-per-week',\n",
    "    'education-num','fnlwgt'])\n",
    "\n",
    "t=s+r\n",
    "v= sklearn.feature_extraction.DictVectorizer(sparse=False,sort=False)\n",
    "census_hot = v.fit_transform(t)\n",
    "census_hot_train = census_hot[:32724,:]\n",
    "census_test = census_hot[32724:,:]\n",
    "\n",
    "census_feat_names = v.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#c_medians = removeneg(census_hot_train)\n",
    "#census_hot_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#v.inverse_transform(census_hot_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self,features,featureNames=None,n=None):\n",
    "        self.features = features\n",
    "        self.n = n\n",
    "        if featureNames:\n",
    "            self.featureNames = featureNames\n",
    "        else:\n",
    "            self.featureNames = features\n",
    "    def select_features(self):        \n",
    "        if self.n:\n",
    "            return random.sample(self.features,self.n)  \n",
    "        else:\n",
    "            return self.features\n",
    "    def sort(self,S,by):\n",
    "        return [S[i] for i in np.argsort(self.data[S,by])]\n",
    "    def train(self,data,labels,depth=-1):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.tree = self.make_tree(data,labels,depth)\n",
    "    def findleaf(self,point,node,v=False):\n",
    "        if node.isLeaf:\n",
    "            return node.cat\n",
    "        if point[node.split_feat]<node.split_val:\n",
    "            if v:\n",
    "                print(\"\\'\"+str(self.featureNames[node.split_feat])+\n",
    "                      '\\'<'+str(node.split_val))\n",
    "            return self.findleaf(point,node.left,v)\n",
    "        else:\n",
    "            if v:\n",
    "                print(\"\\'\"+str(self.featureNames[node.split_feat])+\n",
    "                      '\\'>='+str(node.split_val))\n",
    "            return self.findleaf(point,node.right,v)\n",
    "    def predict(self,data):\n",
    "        return np.apply_along_axis(self.findleaf,1,data,self.tree)\n",
    "    def score(self,v,lab):\n",
    "        return 1-np.count_nonzero(lab-self.predict(v))/lab.shape[0]\n",
    "    def make_tree(self,data,labels,depth=-1):\n",
    "        return self.make_node(list(range(data.shape[0])),depth)\n",
    "    def bfswalk(self):\n",
    "        queue = [self.tree]\n",
    "        while queue :\n",
    "            nextqueue =[]\n",
    "            for n in queue:\n",
    "                print(n, end =\" \")\n",
    "                if not n.isLeaf:\n",
    "                    nextqueue.append(n.left)\n",
    "                    nextqueue.append(n.right)\n",
    "            print(\"\")\n",
    "            queue=nextqueue\n",
    "    def walk(self):\n",
    "        self.dfswalk(self.tree)\n",
    "    def dfswalk(self,node,depth=0,c=''):\n",
    "        if node.isLeaf:\n",
    "            print('|  '*(depth-1)+c+\"class:\"+str(node.cat))\n",
    "        else:\n",
    "            print('|  '*(depth-1)+c+\"feat:\\'\"+\n",
    "                  str(self.featureNames[node.split_feat]) + '\\',val:' +\n",
    "                  str(node.split_val))\n",
    "            self.dfswalk(node.left,depth+1,c=\"<  \")\n",
    "            self.dfswalk(node.right,depth+1,c=\">= \")\n",
    "    \n",
    "                \n",
    "    class Node:\n",
    "        def __init__(self,S,isLeaf,left=None,right=None,\n",
    "                     split_feat=None,split_val=None,cat=None):\n",
    "            self.S = S\n",
    "            self.left = left\n",
    "            self.right = right\n",
    "            self.isLeaf= isLeaf\n",
    "            self.split_feat = split_feat\n",
    "            self.split_val = split_val\n",
    "            self.cat=cat\n",
    "        def __repr__(self):\n",
    "            if self.isLeaf:\n",
    "                return str(self.cat)\n",
    "            else:\n",
    "                return str(self.split_feat) + \",\"+str(self.split_val)        \n",
    "    def is_pure(self,S):\n",
    "        return len(set(self.labels[S]))==1\n",
    "    def xlog(self,x):\n",
    "        return x*math.log(x) if x > 0 else 0\n",
    "    \n",
    "    def entropy(self,left,right):\n",
    "        new = 0\n",
    "        for l in left.keys():\n",
    "            new+=self.xlog(left[l])\n",
    "        for r in right.keys():\n",
    "            new+=self.xlog(right[r])\n",
    "        new -= self.xlog(sum(right.values()))\n",
    "        new -= self.xlog(sum(left.values()))\n",
    "        return new\n",
    "                    \n",
    "    def make_node(self,S,depth=-1):\n",
    "        #print(\"making node with \"+str(S))\n",
    "        if self.is_pure(S) or depth==0: \n",
    "            #print(\"pure node \" + str(self.labels[S]))\n",
    "            return self.Node(S,isLeaf=True,cat=scipy.stats.mode(\n",
    "                self.labels[S])[0][0])\n",
    "            \n",
    "        else:\n",
    "            diff= 0\n",
    "            feat = None\n",
    "            beta = None\n",
    "            for f in self.select_features():   \n",
    "                hist = np.unique(self.data[S,f],return_counts=True)\n",
    "                sl= []\n",
    "                sr = self.sort(S,by=f)\n",
    "                sr.reverse()\n",
    "                propr = collections.Counter(self.labels[S])\n",
    "                srlen = len(sr)\n",
    "                sllen = 0\n",
    "                propl = collections.Counter()\n",
    "                new = 0\n",
    "                i=0\n",
    "                finalsl = sl[:]\n",
    "                finalsr = sr[:]\n",
    "                debt = 0\n",
    "                for val in hist[0][1:]:                   \n",
    "                    j=hist[1][i]                    \n",
    "                    l2=[sr.pop() for i in range(j)]\n",
    "                    sl.extend(l2)\n",
    "                    sam = collections.Counter(self.labels[l2])                    \n",
    "                    debt+=j\n",
    "                    propl2 = propl + sam\n",
    "                    propr2 = propr - sam\n",
    "                    for k in sam.keys():    \n",
    "                        new += self.xlog(propl[k]) -\\\n",
    "                        self.xlog(propl2[k]) +\\\n",
    "                        self.xlog(propr[k]) - \\\n",
    "                        self.xlog(propr2[k])                        \n",
    "                    propl = propl2\n",
    "                    propr = propr2                    \n",
    "                    new += -self.xlog(sllen) +self.xlog(sllen+j) - \\\n",
    "                    self.xlog(srlen) +self.xlog(srlen-j)                   \n",
    "                    sllen +=j\n",
    "                    srlen -=j\n",
    "                    i+=1\n",
    "                    if new<diff:\n",
    "                        diff = new\n",
    "                        beta = val\n",
    "                        feat = f                                                    \n",
    "                        l1 = [finalsr.pop() for i in range(debt)]\n",
    "                        finalsl.extend(l1)\n",
    "                        finalsl2 = finalsl\n",
    "                        finalsr2 = finalsr\n",
    "                        debt =0\n",
    "            if diff==0: \n",
    "                return self.Node(S,isLeaf = True,cat=scipy.stats.mode(\n",
    "                    self.labels[S])[0][0])\n",
    "            if depth>0:\n",
    "                return self.Node(S,isLeaf=False,left=self.make_node(\n",
    "                finalsl2,depth-1),right = self.make_node(\n",
    "                finalsr2,depth-1),split_feat=feat,split_val=beta)\n",
    "            else:\n",
    "                return self.Node(S,isLeaf=False,left=self.make_node(\n",
    "                finalsl2),right = self.make_node(\n",
    "                finalsr2),split_feat=feat,split_val=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self,features,featuresNames,n=1):\n",
    "        self.features = features       \n",
    "        if featuresNames:\n",
    "            self.featureNames = featuresNames\n",
    "        else:\n",
    "            self.featureNames = features\n",
    "        self.numtrees = n\n",
    "    def train(self,data,labels,ss,m,depth=-1):\n",
    "        self.ensemble = []\n",
    "        for i in range(self.numtrees):\n",
    "            datas = np.random.choice(data.shape[0],ss,True)\n",
    "            d =DecisionTree(self.features,self.featureNames,n=int(m))\n",
    "            d.train(data[datas],labels[datas],depth)\n",
    "            self.ensemble.append(d)\n",
    "    def predictpoint(self,point):\n",
    "        l = [d.findleaf(point,d.tree) for d in self.ensemble]\n",
    "        return scipy.stats.mode(l)[0][0]\n",
    "    def predict(self,data):\n",
    "        return np.apply_along_axis(self.predictpoint,1,data)\n",
    "    def score(self,v,lab):\n",
    "        return 1-np.count_nonzero(lab-self.predict(v))/lab.shape[0]\n",
    "    def walk(self):\n",
    "        for d in self.ensemble:\n",
    "            d.walk()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 5,shuffle=True)\n",
    "def j(data,label,names,d=-1):\n",
    "    tree = DecisionTree(list(range(data.shape[1])),names)\n",
    "    score = 0\n",
    "    for train_ind,test_ind in kf.split(data):\n",
    "        tdata = data[train_ind]\n",
    "        tlabel = label[train_ind]\n",
    "        vdata = data[test_ind]\n",
    "        vlabel = label[test_ind]        \n",
    "        tree.train(tdata,tlabel,depth=d)\n",
    "        score += tree.score(vdata,vlabel)\n",
    "\n",
    "    return score/5\n",
    "\n",
    "def k(data,label,names,num_trees,d_bag,f_bag,d=-1):\n",
    "    tree = RandomForest(list(range(data.shape[1])),names,num_trees)\n",
    "    score = 0\n",
    "    for train_ind,test_ind in kf.split(data):\n",
    "        tdata = data[train_ind]\n",
    "        tlabel = label[train_ind]\n",
    "        vdata = data[test_ind]\n",
    "        vlabel = label[test_ind]        \n",
    "        tree.train(tdata,tlabel,d_bag,f_bag,depth=d)\n",
    "        score += tree.score(vdata,vlabel)\n",
    "\n",
    "    return score/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam_feat_names = ['pain','private','bank','money','drug','spam',\n",
    "                   'prescription','creative','height','featured',\n",
    "                   'differ','width','other','energy','business',\n",
    "                   'message','volumes','revision','path','meter',\n",
    "                   'memo','planning','pleased','record','out',';',\n",
    "                   '$','#','!','(','[','&']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spam_t, spam_v, spam_t_label,spam_v_label=train_test_split(\n",
    "    spam_train,spam_labels,test_size=0.2)\n",
    "census_t, census_v, census_t_label, census_v_label = train_test_split(\n",
    "    census_hot_train,census_labels,test_size = 0.2)\n",
    "titanic_t, titanic_v, titanic_t_label, titanic_v_label = train_test_split(\n",
    "    titanic_hot_train,titanic_labels,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam Tree test accuracy: 0.8532777807077686\n",
      "Spam Tree validation accuracy: 0.7897068129086691\n",
      "Spam Forest test accuracy: 0.819418807024946\n",
      "Spam Forest validation accuracy: 0.7937144062434085\n"
     ]
    }
   ],
   "source": [
    "spamtree = DecisionTree(list(range(32)),spam_feat_names)\n",
    "spamforest = RandomForest(list(range(32)),spam_feat_names,10)\n",
    "spamtree.train(spam_t,spam_t_label)\n",
    "spamforest.train(spam_t,spam_t_label,spam_t.shape[0],np.sqrt(\n",
    "    spam_t.shape[1]))\n",
    "\n",
    "print(\"Spam Tree test accuracy:\",spamtree.score(spam_t,spam_t_label))\n",
    "print(\"Spam Tree validation accuracy:\",spamtree.score(\n",
    "    spam_v,spam_v_label))\n",
    "                                                      \n",
    "print(\"Spam Forest test accuracy:\",spamforest.score(spam_t,spam_t_label))\n",
    "print(\"Spam Forest validation accuracy:\",spamforest.score(\n",
    "    spam_v,spam_v_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Census Tree test accuracy: 1.0\n",
      "Census Tree validation accuracy: 0.8108479755538579\n",
      "Census Forest test accuracy: 0.8914397035792048\n",
      "Census Forest validation accuracy: 0.8614209320091673\n"
     ]
    }
   ],
   "source": [
    "censustree = DecisionTree(list(range(108)),census_feat_names)\n",
    "censusforest = RandomForest(list(range(108)),census_feat_names,10)\n",
    "censustree.train(census_t,census_t_label)\n",
    "censusforest.train(census_t,census_t_label,census_t.shape[0],np.sqrt(\n",
    "    census_t.shape[1]))\n",
    "\n",
    "print(\"Census Tree test accuracy:\",censustree.score(\n",
    "    census_t,census_t_label))\n",
    "print(\"Census Tree validation accuracy:\",censustree.score(\n",
    "    census_v,census_v_label))\n",
    "                                                      \n",
    "print(\"Census Forest test accuracy:\",censusforest.score(\n",
    "    census_t,census_t_label))\n",
    "print(\"Census Forest validation accuracy:\",censusforest.score(\n",
    "    census_v,census_v_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic Tree test accuracy: 0.9975\n",
      "Titanic Tree validation accuracy: 0.8200000000000001\n",
      "Titanic Forest test accuracy: 0.86125\n",
      "Titanic Forest validation accuracy: 0.8049999999999999\n"
     ]
    }
   ],
   "source": [
    "titanictree = DecisionTree(list(range(1129)),titanic_feat_names)\n",
    "titanicforest = RandomForest(list(range(1129)),titanic_feat_names,10)\n",
    "titanictree.train(titanic_t,titanic_t_label)\n",
    "titanicforest.train(titanic_t,titanic_t_label,titanic_t.shape[0],np.sqrt(\n",
    "    titanic_t.shape[1]))\n",
    "\n",
    "print(\"Titanic Tree test accuracy:\",titanictree.score(\n",
    "    titanic_t,titanic_t_label))\n",
    "print(\"Titanic Tree validation accuracy:\",titanictree.score(\n",
    "    titanic_v,titanic_v_label))\n",
    "                                                      \n",
    "print(\"Titanic Forest test accuracy:\",titanicforest.score(\n",
    "    titanic_t,titanic_t_label))\n",
    "print(\"Titanic Forest validation accuracy:\",titanicforest.score(\n",
    "    titanic_v,titanic_v_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for c in [1,2,3,4,5,10,15,20,25,30,40]:\n",
    "#    print(c,j(spam_train,spam_labels,spam_feat_names,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for k in [50]:\n",
    "#    print(c,k(spam_train,spam_labels,spam_feat_names,c,spam_train.shape[0],np.sqrt(spam_train.shape[1]),20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#kaggle\n",
    "spamforest = RandomForest(list(range(32)),spam_feat_names,50)\n",
    "spamforest.train(spam_train,spam_labels,spam_train.shape[0],np.sqrt(\n",
    "    spam_train.shape[1]),depth=20)\n",
    "censusforest = RandomForest(list(range(108)),census_feat_names,10)\n",
    "censusforest.train(\n",
    "    census_hot_train,census_labels,census_hot_train.shape[0],np.sqrt(\n",
    "    census_hot_train.shape[1]))\n",
    "titanicforest = RandomForest(list(range(1129)),titanic_feat_names,20)\n",
    "titanicforest.train(\n",
    "    titanic_hot_train,titanic_labels,titanic_hot_train.shape[0],7*np.sqrt(\n",
    "    titanic_hot_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output(self,path,data,zindex=0):\n",
    "        np.savetxt(\n",
    "        path, np.column_stack(\n",
    "        (np.array(\n",
    "            list(zindex+np.arange(data.shape[0]))),self.predict(\n",
    "            data))).astype(int), \n",
    "        fmt =\"%i\",delimiter = \",\", \n",
    "        header = \"Id,Category\",comments = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output(spamforest,\"spamkaggle.csv\",spam_test,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![spam](spamkaggle.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output(censusforest,\"censuskaggle.csv\",census_test,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![census](censuskaggle.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output(titanicforest,\"titanicforest.csv\",titanic_test,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![titanic](titanickaggle.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spamtree2 = DecisionTree(list(range(32)),spam_feat_names)\n",
    "spamtree2.train(spam_train,spam_labels)\n",
    "spamforest2 = RandomForest(list(range(32)),spam_feat_names,64)\n",
    "spamforest2.train(spam_train,spam_labels,spam_train.shape[0],np.sqrt(\n",
    "    spam_train.shape[1]),depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'!'<1.0\n",
      "'('<1.0\n",
      "'meter'<1.0\n",
      "';'<2.0\n",
      "'creative'<1.0\n",
      "'energy'<1.0\n",
      "'money'<1.0\n",
      "'pain'<1.0\n",
      "'$'<1.0\n",
      "'&'<1.0\n",
      "'prescription'<1.0\n",
      "'memo'<1.0\n",
      "'volumes'<1.0\n",
      "'['<1.0\n",
      "'bank'<2.0\n",
      "'spam'<1.0\n",
      "'business'<1.0\n",
      "'private'<1.0\n",
      "'drug'<1.0\n",
      "'planning'<1.0\n",
      "'revision'<1.0\n",
      "'differ'<1.0\n",
      "'path'<1.0\n",
      "'other'<2.0\n",
      "'message'>=1.0\n",
      "'#'>=1.0\n",
      "'out'<2.0\n",
      "'#'<3.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classify spam\n",
    "spamtree2.findleaf(spam_train[0],spamtree.tree,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'!'<1.0\n",
      "'('>=1.0\n",
      "'money'<1.0\n",
      "'featured'<1.0\n",
      "'energy'<1.0\n",
      "'$'>=1.0\n",
      "';'<4.0\n",
      "'pain'<1.0\n",
      "'volumes'<1.0\n",
      "'private'<1.0\n",
      "'('<2.0\n",
      "'$'>=2.0\n",
      "'&'<3.0\n",
      "'$'<3.0\n",
      "';'>=1.0\n",
      "'bank'<3.0\n",
      "'#'<2.0\n",
      "'out'<1.0\n",
      "'message'>=1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classify ham\n",
    "spamtree2.findleaf(spam_train[-1],spamtree.tree,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('!', 1.0): 11,\n",
       "         ('$', 1.0): 1,\n",
       "         ('&', 1.0): 1,\n",
       "         ('(', 1.0): 8,\n",
       "         ('creative', 1.0): 3,\n",
       "         ('differ', 1.0): 3,\n",
       "         ('energy', 1.0): 3,\n",
       "         ('featured', 1.0): 5,\n",
       "         ('memo', 1.0): 1,\n",
       "         ('meter', 1.0): 5,\n",
       "         ('money', 1.0): 12,\n",
       "         ('prescription', 1.0): 4,\n",
       "         ('spam', 1.0): 2,\n",
       "         ('volumes', 1.0): 5})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#most often split\n",
    "c = collections.Counter()\n",
    "for t in spamforest2.ensemble:\n",
    "    c[(spamforest2.featureNames[t.tree.split_feat],t.tree.split_val)] +=1\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "censustree2 = DecisionTree(list(range(108)),census_feat_names)\n",
    "censustree2.train(census_t,census_t_label)\n",
    "censusforest2 = RandomForest(list(range(108)),census_feat_names,216)\n",
    "censusforest2.train(\n",
    "    census_hot_train,census_labels,census_hot_train.shape[0],np.sqrt(\n",
    "    census_hot_train.shape[1]),depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'marital-status=Married-civ-spouse'>=1.0\n",
      "'education-num'<12.0\n",
      "'capital-gain'>=5178.0\n",
      "'age'<61.0\n",
      "'native-country=United-States'>=1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classify 1\n",
    "censustree2.findleaf(census_hot_train[4],censustree.tree,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'marital-status=Married-civ-spouse'<1.0\n",
      "'capital-gain'<7430.0\n",
      "'education-num'<13.0\n",
      "'age'>=34.0\n",
      "'hours-per-week'>=42.0\n",
      "'capital-loss'<2444.0\n",
      "'education-num'<7.0\n",
      "'fnlwgt'>=50837.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classify 0\n",
    "censustree2.findleaf(census_hot_train[0],censustree.tree,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('age', 28.0): 5,\n",
       "         ('age', 29.0): 9,\n",
       "         ('capital-gain', 5178.0): 8,\n",
       "         ('capital-gain', 7262.0): 5,\n",
       "         ('capital-gain', 7298.0): 1,\n",
       "         ('capital-loss', 1825.0): 5,\n",
       "         ('capital-loss', 1848.0): 3,\n",
       "         ('education-num', 13.0): 14,\n",
       "         ('education=11th', 1.0): 2,\n",
       "         ('education=Bachelors', 1.0): 3,\n",
       "         ('education=Doctorate', 1.0): 1,\n",
       "         ('education=HS-grad', 1.0): 1,\n",
       "         ('education=Masters', 1.0): 2,\n",
       "         ('education=Prof-school', 1.0): 2,\n",
       "         ('hours-per-week', 41.0): 4,\n",
       "         ('hours-per-week', 42.0): 5,\n",
       "         ('hours-per-week', 43.0): 1,\n",
       "         ('marital-status=Divorced', 1.0): 2,\n",
       "         ('marital-status=Married-civ-spouse', 1.0): 21,\n",
       "         ('marital-status=Never-married', 1.0): 18,\n",
       "         ('native-country=Mexico', 1.0): 1,\n",
       "         ('occupation=?', 1.0): 2,\n",
       "         ('occupation=Adm-clerical', 1.0): 1,\n",
       "         ('occupation=Exec-managerial', 1.0): 11,\n",
       "         ('occupation=Handlers-cleaners', 1.0): 1,\n",
       "         ('occupation=Machine-op-inspct', 1.0): 1,\n",
       "         ('occupation=Other-service', 1.0): 7,\n",
       "         ('occupation=Prof-specialty', 1.0): 7,\n",
       "         ('race=Black', 1.0): 2,\n",
       "         ('race=White', 1.0): 3,\n",
       "         ('relationship=Husband', 1.0): 17,\n",
       "         ('relationship=Not-in-family', 1.0): 6,\n",
       "         ('relationship=Own-child', 1.0): 19,\n",
       "         ('relationship=Unmarried', 1.0): 10,\n",
       "         ('sex=Female', 1.0): 9,\n",
       "         ('sex=Male', 1.0): 5,\n",
       "         ('workclass=Federal-gov', 1.0): 1,\n",
       "         ('workclass=Self-emp-inc', 1.0): 1})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#most often split\n",
    "c = collections.Counter()\n",
    "for t in censusforest2.ensemble:\n",
    "    c[(censusforest2.featureNames[t.tree.split_feat],t.tree.split_val)] +=1\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def g(z):\n",
    "    censustree = DecisionTree(list(range(108)),census_feat_names)\n",
    "    censustree.train(census_t,census_t_label,depth = z)\n",
    "    return censustree.score(census_v,census_v_label)\n",
    "x = [1,2,3,5,10,15,20,25,30,35,40]\n",
    "y = [g(z) for z in x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAHwCAYAAABTxu5FAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1adfa077a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,y)\n",
    "plt.title('Problem 6d')\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.xlabel(\"Depth of Tree\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#titanic shallow tree\n",
    "titanictree2 = DecisionTree(list(range(1129)),titanic_feat_names)\n",
    "titanictree2.train(titanic_hot_train,titanic_labels,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat:'sex=male',val:1.0\n",
      "<  feat:'pclass',val:3.0\n",
      "|  <  feat:'cabin=C22 C26',val:1.0\n",
      "|  |  <  class:1\n",
      "|  |  >= class:0\n",
      "|  >= feat:'fare',val:23.45\n",
      "|  |  <  class:1\n",
      "|  |  >= class:0\n",
      ">= feat:'cabin=-1',val:1.0\n",
      "|  <  feat:'age',val:18.0\n",
      "|  |  <  class:1\n",
      "|  |  >= class:0\n",
      "|  >= feat:'age',val:4.0\n",
      "|  |  <  class:1\n",
      "|  |  >= class:0\n"
     ]
    }
   ],
   "source": [
    "titanictree2.walk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import time\n",
    "import collections\n",
    "import random\n",
    "import timeit\n",
    "import math\n",
    "\n",
    "import scipy,sklearn,pylab\n",
    "from scipy import io\n",
    "\n",
    "from sklearn import model_selection,covariance\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "matplotlib.rcParams['xtick.direction'] = 'out'\n",
    "matplotlib.rcParams['ytick.direction'] = 'out'\n",
    "matplotlib.rcParams['figure.figsize'] = (9,8)\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "def readfile(path, cols):\n",
    "    with open(path) as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        q=list(reader)\n",
    "    s = [dict(([a,'-1'] if (x=='') else [a,x]) for a,x in b.items()) for b in q]\n",
    "    return [dict((\n",
    "        [a,float(x)] if a in cols else [a,x]) for a,x in b.items()) for b in s]\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "def removeneg(data,n=None):    \n",
    "    def f(data,n=None):\n",
    "        a = data[data!=-1]\n",
    "        if n:\n",
    "            m=n\n",
    "        else:\n",
    "            m = np.median(a)\n",
    "        for i in range(len(data)):\n",
    "            if (data==-1)[i]:\n",
    "                data[i]=m\n",
    "        return m\n",
    "    l = []\n",
    "    if n:\n",
    "        for i in range(data.shape[1]):\n",
    "            f(data[:,i],n[i])\n",
    "    else:\n",
    "         for i in range(data.shape[1]):\n",
    "            l.append(f(data[:,i]))\n",
    "    return l\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "s = readfile(\"hw5_titanic_dist/titanic_training.csv\",[\n",
    "    'pclass','age','sibsp','parch','fare'])\n",
    "\n",
    "titanic_labels = np.array([z.pop('survived') for z in s]).astype(\n",
    "    float).astype(int)\n",
    "r = readfile(\"hw5_titanic_dist/titanic_testing_data.csv\",[\n",
    "    'pclass','age','sibsp','parch','fare'])\n",
    "\n",
    "t = s+r\n",
    "\n",
    "v= sklearn.feature_extraction.DictVectorizer(sparse=False,sort=False)\n",
    "titanic_hot = v.fit_transform(t)\n",
    "titanic_hot_train = titanic_hot[:1000,:]\n",
    "titanic_test = titanic_hot[1000:,:]\n",
    "\n",
    "titanic_feat_names = v.get_feature_names()\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "t_medians = removeneg(titanic_hot_train)\n",
    "removeneg(titanic_test,t_medians)\n",
    "#titanic_hot_train\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "#v.inverse_transform(titanic_hot_train)\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "spam= scipy.io.loadmat(\"hw5_spam_dist/dist/spam_data\")\n",
    "#spam\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "spam_train = spam['training_data']\n",
    "spam_labels = spam['training_labels'][0]\n",
    "spam_test = spam['test_data']\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "s= readfile(\"hw5_census_dist/train_data.csv\",[\n",
    "    'capital-gain','capital-loss','age','hours-per-week',\n",
    "    'education-num','fnlwgt'])\n",
    "census_labels = np.array([z.pop('label') for z in s]).astype(int)\n",
    "r = readfile(\"hw5_census_dist/test_data.csv\",[\n",
    "    'capital-gain','capital-loss','age','hours-per-week',\n",
    "    'education-num','fnlwgt'])\n",
    "\n",
    "t=s+r\n",
    "v= sklearn.feature_extraction.DictVectorizer(sparse=False,sort=False)\n",
    "census_hot = v.fit_transform(t)\n",
    "census_hot_train = census_hot[:32724,:]\n",
    "census_test = census_hot[32724:,:]\n",
    "\n",
    "census_feat_names = v.get_feature_names()\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "#c_medians = removeneg(census_hot_train)\n",
    "#census_hot_train\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "#v.inverse_transform(census_hot_train)\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self,features,featureNames=None,n=None):\n",
    "        self.features = features\n",
    "        self.n = n\n",
    "        if featureNames:\n",
    "            self.featureNames = featureNames\n",
    "        else:\n",
    "            self.featureNames = features\n",
    "    def select_features(self):        \n",
    "        if self.n:\n",
    "            return random.sample(self.features,self.n)  \n",
    "        else:\n",
    "            return self.features\n",
    "    def sort(self,S,by):\n",
    "        return [S[i] for i in np.argsort(self.data[S,by])]\n",
    "    def train(self,data,labels,depth=-1):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.tree = self.make_tree(data,labels,depth)\n",
    "    def findleaf(self,point,node,v=False):\n",
    "        if node.isLeaf:\n",
    "            return node.cat\n",
    "        if point[node.split_feat]<node.split_val:\n",
    "            if v:\n",
    "                print(\"\\'\"+str(self.featureNames[node.split_feat])+\n",
    "                      '\\'<'+str(node.split_val))\n",
    "            return self.findleaf(point,node.left,v)\n",
    "        else:\n",
    "            if v:\n",
    "                print(\"\\'\"+str(self.featureNames[node.split_feat])+\n",
    "                      '\\'>='+str(node.split_val))\n",
    "            return self.findleaf(point,node.right,v)\n",
    "    def predict(self,data):\n",
    "        return np.apply_along_axis(self.findleaf,1,data,self.tree)\n",
    "    def score(self,v,lab):\n",
    "        return 1-np.count_nonzero(lab-self.predict(v))/lab.shape[0]\n",
    "    def make_tree(self,data,labels,depth=-1):\n",
    "        return self.make_node(list(range(data.shape[0])),depth)\n",
    "    def bfswalk(self):\n",
    "        queue = [self.tree]\n",
    "        while queue :\n",
    "            nextqueue =[]\n",
    "            for n in queue:\n",
    "                print(n, end =\" \")\n",
    "                if not n.isLeaf:\n",
    "                    nextqueue.append(n.left)\n",
    "                    nextqueue.append(n.right)\n",
    "            print(\"\")\n",
    "            queue=nextqueue\n",
    "    def walk(self):\n",
    "        self.dfswalk(self.tree)\n",
    "    def dfswalk(self,node,depth=0,c=''):\n",
    "        if node.isLeaf:\n",
    "            print('|  '*(depth-1)+c+\"class:\"+str(node.cat))\n",
    "        else:\n",
    "            print('|  '*(depth-1)+c+\"feat:\\'\"+\n",
    "                  str(self.featureNames[node.split_feat]) + '\\',val:' +\n",
    "                  str(node.split_val))\n",
    "            self.dfswalk(node.left,depth+1,c=\"<  \")\n",
    "            self.dfswalk(node.right,depth+1,c=\">= \")\n",
    "    \n",
    "                \n",
    "    class Node:\n",
    "        def __init__(self,S,isLeaf,left=None,right=None,\n",
    "                     split_feat=None,split_val=None,cat=None):\n",
    "            self.S = S\n",
    "            self.left = left\n",
    "            self.right = right\n",
    "            self.isLeaf= isLeaf\n",
    "            self.split_feat = split_feat\n",
    "            self.split_val = split_val\n",
    "            self.cat=cat\n",
    "        def __repr__(self):\n",
    "            if self.isLeaf:\n",
    "                return str(self.cat)\n",
    "            else:\n",
    "                return str(self.split_feat) + \",\"+str(self.split_val)        \n",
    "    def is_pure(self,S):\n",
    "        return len(set(self.labels[S]))==1\n",
    "    def xlog(self,x):\n",
    "        return x*math.log(x) if x > 0 else 0\n",
    "    \n",
    "    def entropy(self,left,right):\n",
    "        new = 0\n",
    "        for l in left.keys():\n",
    "            new+=self.xlog(left[l])\n",
    "        for r in right.keys():\n",
    "            new+=self.xlog(right[r])\n",
    "        new -= self.xlog(sum(right.values()))\n",
    "        new -= self.xlog(sum(left.values()))\n",
    "        return new\n",
    "                    \n",
    "    def make_node(self,S,depth=-1):\n",
    "        #print(\"making node with \"+str(S))\n",
    "        if self.is_pure(S) or depth==0: \n",
    "            #print(\"pure node \" + str(self.labels[S]))\n",
    "            return self.Node(S,isLeaf=True,cat=scipy.stats.mode(\n",
    "                self.labels[S])[0][0])\n",
    "            \n",
    "        else:\n",
    "            diff= 0\n",
    "            feat = None\n",
    "            beta = None\n",
    "            for f in self.select_features():   \n",
    "                hist = np.unique(self.data[S,f],return_counts=True)\n",
    "                sl= []\n",
    "                sr = self.sort(S,by=f)\n",
    "                sr.reverse()\n",
    "                propr = collections.Counter(self.labels[S])\n",
    "                srlen = len(sr)\n",
    "                sllen = 0\n",
    "                propl = collections.Counter()\n",
    "                new = 0\n",
    "                i=0\n",
    "                finalsl = sl[:]\n",
    "                finalsr = sr[:]\n",
    "                debt = 0\n",
    "                for val in hist[0][1:]:                   \n",
    "                    j=hist[1][i]                    \n",
    "                    l2=[sr.pop() for i in range(j)]\n",
    "                    sl.extend(l2)\n",
    "                    sam = collections.Counter(self.labels[l2])                    \n",
    "                    debt+=j\n",
    "                    propl2 = propl + sam\n",
    "                    propr2 = propr - sam\n",
    "                    for k in sam.keys():    \n",
    "                        new += self.xlog(propl[k]) -                        \n",
    "                        self.xlog(propl2[k]) +                        \n",
    "                        self.xlog(propr[k]) -                         \n",
    "                        self.xlog(propr2[k])                        \n",
    "                    propl = propl2\n",
    "                    propr = propr2                    \n",
    "                    new += -self.xlog(sllen) +self.xlog(sllen+j) -                     \n",
    "                    self.xlog(srlen) +self.xlog(srlen-j)                   \n",
    "                    sllen +=j\n",
    "                    srlen -=j\n",
    "                    i+=1\n",
    "                    if new<diff:\n",
    "                        diff = new\n",
    "                        beta = val\n",
    "                        feat = f                                                    \n",
    "                        l1 = [finalsr.pop() for i in range(debt)]\n",
    "                        finalsl.extend(l1)\n",
    "                        finalsl2 = finalsl\n",
    "                        finalsr2 = finalsr\n",
    "                        debt =0\n",
    "            if diff==0: \n",
    "                return self.Node(S,isLeaf = True,cat=scipy.stats.mode(\n",
    "                    self.labels[S])[0][0])\n",
    "            if depth>0:\n",
    "                return self.Node(S,isLeaf=False,left=self.make_node(\n",
    "                finalsl2,depth-1),right = self.make_node(\n",
    "                finalsr2,depth-1),split_feat=feat,split_val=beta)\n",
    "            else:\n",
    "                return self.Node(S,isLeaf=False,left=self.make_node(\n",
    "                finalsl2),right = self.make_node(\n",
    "                finalsr2),split_feat=feat,split_val=beta)\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self,features,featuresNames,n=1):\n",
    "        self.features = features       \n",
    "        if featuresNames:\n",
    "            self.featureNames = featuresNames\n",
    "        else:\n",
    "            self.featureNames = features\n",
    "        self.numtrees = n\n",
    "    def train(self,data,labels,ss,m,depth=-1):\n",
    "        self.ensemble = []\n",
    "        for i in range(self.numtrees):\n",
    "            datas = np.random.choice(data.shape[0],ss,True)\n",
    "            d =DecisionTree(self.features,self.featureNames,n=int(m))\n",
    "            d.train(data[datas],labels[datas],depth)\n",
    "            self.ensemble.append(d)\n",
    "    def predictpoint(self,point):\n",
    "        l = [d.findleaf(point,d.tree) for d in self.ensemble]\n",
    "        return scipy.stats.mode(l)[0][0]\n",
    "    def predict(self,data):\n",
    "        return np.apply_along_axis(self.predictpoint,1,data)\n",
    "    def score(self,v,lab):\n",
    "        return 1-np.count_nonzero(lab-self.predict(v))/lab.shape[0]\n",
    "    def walk(self):\n",
    "        for d in self.ensemble:\n",
    "            d.walk()\n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "kf = KFold(n_splits = 5,shuffle=True)\n",
    "def j(data,label,names,d=-1):\n",
    "    tree = DecisionTree(list(range(data.shape[1])),names)\n",
    "    score = 0\n",
    "    for train_ind,test_ind in kf.split(data):\n",
    "        tdata = data[train_ind]\n",
    "        tlabel = label[train_ind]\n",
    "        vdata = data[test_ind]\n",
    "        vlabel = label[test_ind]        \n",
    "        tree.train(tdata,tlabel,depth=d)\n",
    "        score += tree.score(vdata,vlabel)\n",
    "\n",
    "    return score/5\n",
    "\n",
    "def k(data,label,names,num_trees,d_bag,f_bag,d=-1):\n",
    "    tree = RandomForest(list(range(data.shape[1])),names,num_trees)\n",
    "    score = 0\n",
    "    for train_ind,test_ind in kf.split(data):\n",
    "        tdata = data[train_ind]\n",
    "        tlabel = label[train_ind]\n",
    "        vdata = data[test_ind]\n",
    "        vlabel = label[test_ind]        \n",
    "        tree.train(tdata,tlabel,d_bag,f_bag,depth=d)\n",
    "        score += tree.score(vdata,vlabel)\n",
    "\n",
    "    return score/5\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "spam_feat_names = ['pain','private','bank','money','drug','spam',\n",
    "                   'prescription','creative','height','featured',\n",
    "                   'differ','width','other','energy','business',\n",
    "                   'message','volumes','revision','path','meter',\n",
    "                   'memo','planning','pleased','record','out',';',\n",
    "                   '$','#','!','(','[','&']\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "spam_t, spam_v, spam_t_label,spam_v_label=train_test_split(\n",
    "    spam_train,spam_labels,test_size=0.2)\n",
    "census_t, census_v, census_t_label, census_v_label = train_test_split(\n",
    "    census_hot_train,census_labels,test_size = 0.2)\n",
    "titanic_t, titanic_v, titanic_t_label, titanic_v_label = train_test_split(\n",
    "    titanic_hot_train,titanic_labels,test_size = 0.2)\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "spamtree = DecisionTree(list(range(32)),spam_feat_names)\n",
    "spamforest = RandomForest(list(range(32)),spam_feat_names,10)\n",
    "spamtree.train(spam_t,spam_t_label)\n",
    "spamforest.train(spam_t,spam_t_label,spam_t.shape[0],np.sqrt(\n",
    "    spam_t.shape[1]))\n",
    "\n",
    "print(\"Spam Tree test accuracy:\",spamtree.score(spam_t,spam_t_label))\n",
    "print(\"Spam Tree validation accuracy:\",spamtree.score(\n",
    "    spam_v,spam_v_label))\n",
    "                                                      \n",
    "print(\"Spam Forest test accuracy:\",spamforest.score(spam_t,spam_t_label))\n",
    "print(\"Spam Forest validation accuracy:\",spamforest.score(\n",
    "    spam_v,spam_v_label))\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "censustree = DecisionTree(list(range(108)),census_feat_names)\n",
    "censusforest = RandomForest(list(range(108)),census_feat_names,10)\n",
    "censustree.train(census_t,census_t_label)\n",
    "censusforest.train(census_t,census_t_label,census_t.shape[0],np.sqrt(\n",
    "    census_t.shape[1]))\n",
    "\n",
    "print(\"Census Tree test accuracy:\",censustree.score(\n",
    "    census_t,census_t_label))\n",
    "print(\"Census Tree validation accuracy:\",censustree.score(\n",
    "    census_v,census_v_label))\n",
    "                                                      \n",
    "print(\"Census Forest test accuracy:\",censusforest.score(\n",
    "    census_t,census_t_label))\n",
    "print(\"Census Forest validation accuracy:\",censusforest.score(\n",
    "    census_v,census_v_label))\n",
    "\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "titanictree = DecisionTree(list(range(1129)),titanic_feat_names)\n",
    "titanicforest = RandomForest(list(range(1129)),titanic_feat_names,10)\n",
    "titanictree.train(titanic_t,titanic_t_label)\n",
    "titanicforest.train(titanic_t,titanic_t_label,titanic_t.shape[0],np.sqrt(\n",
    "    titanic_t.shape[1]))\n",
    "\n",
    "print(\"Titanic Tree test accuracy:\",titanictree.score(\n",
    "    titanic_t,titanic_t_label))\n",
    "print(\"Titanic Tree validation accuracy:\",titanictree.score(\n",
    "    titanic_v,titanic_v_label))\n",
    "                                                      \n",
    "print(\"Titanic Forest test accuracy:\",titanicforest.score(\n",
    "    titanic_t,titanic_t_label))\n",
    "print(\"Titanic Forest validation accuracy:\",titanicforest.score(\n",
    "    titanic_v,titanic_v_label))\n",
    "\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "#for c in [1,2,3,4,5,10,15,20,25,30,40]:\n",
    "#    print(c,j(spam_train,spam_labels,spam_feat_names,c))\n",
    "\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "#for k in [50]:\n",
    "#    print(c,k(spam_train,spam_labels,spam_feat_names,c,spam_train.shape[0],np.sqrt(spam_train.shape[1]),20))\n",
    "\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "#kaggle\n",
    "spamforest = RandomForest(list(range(32)),spam_feat_names,50)\n",
    "spamforest.train(spam_train,spam_labels,spam_train.shape[0],np.sqrt(\n",
    "    spam_train.shape[1]),depth=20)\n",
    "censusforest = RandomForest(list(range(108)),census_feat_names,10)\n",
    "censusforest.train(\n",
    "    census_hot_train,census_labels,census_hot_train.shape[0],np.sqrt(\n",
    "    census_hot_train.shape[1]))\n",
    "titanicforest = RandomForest(list(range(1129)),titanic_feat_names,20)\n",
    "titanicforest.train(\n",
    "    titanic_hot_train,titanic_labels,titanic_hot_train.shape[0],7*np.sqrt(\n",
    "    titanic_hot_train.shape[1]))\n",
    "\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "def output(self,path,data,zindex=0):\n",
    "        np.savetxt(\n",
    "        path, np.column_stack(\n",
    "        (np.array(\n",
    "            list(zindex+np.arange(data.shape[0]))),self.predict(\n",
    "            data))).astype(int), \n",
    "        fmt =\"%i\",delimiter = \",\", \n",
    "        header = \"Id,Category\",comments = \"\")\n",
    "\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "output(spamforest,\"spamkaggle.csv\",spam_test,0)\n",
    "\n",
    "\n",
    "# ![spam](spamkaggle.PNG)\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "output(censusforest,\"censuskaggle.csv\",census_test,1)\n",
    "\n",
    "\n",
    "# ![census](censuskaggle.PNG)\n",
    "\n",
    "# In[26]:\n",
    "\n",
    "output(titanicforest,\"titanicforest.csv\",titanic_test,1)\n",
    "\n",
    "\n",
    "# ![titanic](titanickaggle.PNG)\n",
    "\n",
    "# In[27]:\n",
    "\n",
    "spamtree2 = DecisionTree(list(range(32)),spam_feat_names)\n",
    "spamtree2.train(spam_train,spam_labels)\n",
    "spamforest2 = RandomForest(list(range(32)),spam_feat_names,64)\n",
    "spamforest2.train(spam_train,spam_labels,spam_train.shape[0],np.sqrt(\n",
    "    spam_train.shape[1]),depth=1)\n",
    "\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "#classify spam\n",
    "spamtree2.findleaf(spam_train[0],spamtree.tree,True)\n",
    "\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "#classify ham\n",
    "spamtree2.findleaf(spam_train[-1],spamtree.tree,True)\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "#most often split\n",
    "c = collections.Counter()\n",
    "for t in spamforest2.ensemble:\n",
    "    c[(spamforest2.featureNames[t.tree.split_feat],t.tree.split_val)] +=1\n",
    "c\n",
    "\n",
    "\n",
    "# In[31]:\n",
    "\n",
    "censustree2 = DecisionTree(list(range(108)),census_feat_names)\n",
    "censustree2.train(census_t,census_t_label)\n",
    "censusforest2 = RandomForest(list(range(108)),census_feat_names,216)\n",
    "censusforest2.train(\n",
    "    census_hot_train,census_labels,census_hot_train.shape[0],np.sqrt(\n",
    "    census_hot_train.shape[1]),depth=1)\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "#classify 1\n",
    "censustree2.findleaf(census_hot_train[4],censustree.tree,True)\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "#classify 0\n",
    "censustree2.findleaf(census_hot_train[0],censustree.tree,True)\n",
    "\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "#most often split\n",
    "c = collections.Counter()\n",
    "for t in censusforest2.ensemble:\n",
    "    c[(censusforest2.featureNames[t.tree.split_feat],t.tree.split_val)] +=1\n",
    "c\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "def g(z):\n",
    "    censustree = DecisionTree(list(range(108)),census_feat_names)\n",
    "    censustree.train(census_t,census_t_label,depth = z)\n",
    "    return censustree.score(census_v,census_v_label)\n",
    "x = [1,2,3,5,10,15,20,25,30,35,40]\n",
    "y = [g(z) for z in x]\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.title('Problem 6d')\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.xlabel(\"Number of Trees\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[37]:\n",
    "\n",
    "#titanic shallow tree\n",
    "titanictree2 = DecisionTree(list(range(1129)),titanic_feat_names)\n",
    "titanictree2.train(titanic_hot_train,titanic_labels,3)\n",
    "\n",
    "\n",
    "# In[38]:\n",
    "\n",
    "titanictree2.walk()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
